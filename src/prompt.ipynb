{
 "cells": [
  {
   "cell_type": "code",
   "id": "14d07995",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T21:56:30.976216100Z",
     "start_time": "2026-02-03T21:56:30.953904500Z"
    }
   },
   "source": [
    "import gc\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "from transformers import Trainer, TrainingArguments,TrainerCallback, EarlyStoppingCallback\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import load_dataset, DatasetDict"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "ddb94a94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T21:56:31.057664600Z",
     "start_time": "2026-02-03T21:56:31.002072300Z"
    }
   },
   "source": [
    "SEED = 42\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MODEL_NAME = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "DATASET_NAME = \"stanfordnlp/imdb\"\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED) # if using CPU\n",
    "torch.cuda.manual_seed(SEED) # if using single-GPU\n",
    "torch.cuda.manual_seed_all(SEED) # if using multi-GPU\n",
    "torch.backends.cudnn.deterministic = True # deterministic mode\n",
    "torch.backends.cudnn.benchmark = False # disable auto-tuner to find the best algorithm to use for your hardware\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow TensorFloat-32 on matmul operations\n",
    "torch.backends.cudnn.allow_tf32  = True # allow TensorFloat-32 on convolution operations\n",
    "# torch.autograd.set_detect_anomaly(True) # keep this commented out for speed unless debugging NaN\n",
    "print(\"Using device: \", DEVICE)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "7d01934c",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "id": "6a3f09fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T21:56:32.346536400Z",
     "start_time": "2026-02-03T21:56:31.060859400Z"
    }
   },
   "source": [
    "dataset = load_dataset(DATASET_NAME)\n",
    "print(dataset)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T21:56:32.481412300Z",
     "start_time": "2026-02-03T21:56:32.406976100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##%% Prompt Strategies\n",
    "def truncate_few_shot(example):\n",
    "    # Few-shot prompt design: providing examples to the LLM\n",
    "    # Take the first 50 words of the review to keep the prompt short\n",
    "    review_segment = \" \".join(example['text'].split()[:50])\n",
    "    prompt = (\n",
    "        \"You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\n\"\n",
    "        \"Review: The movie was terrible, boring and too long.\\n\"\n",
    "        \"Sentiment: NEGATIVE\\n\\n\"\n",
    "        \"Review: Absolutely fantastic! I loved every minute of it.\\n\"\n",
    "        \"Sentiment: POSITIVE\\n\\n\"\n",
    "        f\"Review: {review_segment}\\n\"\n",
    "        \"Sentiment:\"\n",
    "    )\n",
    "    return {'text': prompt, 'label': example['label']}\n",
    "\n",
    "small_few_shot = dataset['train'].shuffle(seed=SEED).select(range(128, 160)).map(truncate_few_shot)\n",
    "print(small_few_shot)\n",
    "print(small_few_shot[:10])\n",
    "print(f\"Test size: {len(small_few_shot)}\")"
   ],
   "id": "734a8f31b11bc038",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 32\n",
      "})\n",
      "{'text': [\"You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: The movie was terrible, boring and too long.\\nSentiment: NEGATIVE\\n\\nReview: Absolutely fantastic! I loved every minute of it.\\nSentiment: POSITIVE\\n\\nReview: Thomas Clay has been mixing with the wrong types. That's the trouble with young people these days, they have no respect.<br /><br />Seriously this film should be avoided at all costs. The action in the main body of the film is slow and rather stodgy and ambles to the drug\\nSentiment:\", \"You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: The movie was terrible, boring and too long.\\nSentiment: NEGATIVE\\n\\nReview: Absolutely fantastic! I loved every minute of it.\\nSentiment: POSITIVE\\n\\nReview: Emily Watson's Natalia is absolutely the most loving and romantic lead character I have ever seen on a screen. She is the queen of this film beyond all doubt. Or, is she transmuted to the king? The internecine weaving of the chess games and the families' struggles for control, power,\\nSentiment:\", \"You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: The movie was terrible, boring and too long.\\nSentiment: NEGATIVE\\n\\nReview: Absolutely fantastic! I loved every minute of it.\\nSentiment: POSITIVE\\n\\nReview: This apology for a movie is about absolutely nothing! Rachel Griffiths must have needed the money. The film must have been made on a very low budget, because the lighting was non existent. I made a vow if I ever see Pete Postlesumthingor other I'll commit suicide. I'd be happy\\nSentiment:\", 'You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: The movie was terrible, boring and too long.\\nSentiment: NEGATIVE\\n\\nReview: Absolutely fantastic! I loved every minute of it.\\nSentiment: POSITIVE\\n\\nReview: Can you say \"All shock, no plot?\" There were so many unexplored directions in this movie. There was no history about the room other than the deaths. *WHY* was it evil? What made it that way? Why an \"hour\" countdown? Then, there were the unexplored things hinted at; for example\\nSentiment:', \"You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: The movie was terrible, boring and too long.\\nSentiment: NEGATIVE\\n\\nReview: Absolutely fantastic! I loved every minute of it.\\nSentiment: POSITIVE\\n\\nReview: Watched this with my girlfriend after stumbling over it while zaping channels.<br /><br />I guess we both hoped for some kind of happy family cute Christmas movie, but were extremely disappointed.<br /><br />the actor playing the soldier, seems to have 0 emotion whatsoever, his face looks the same, whether he's\\nSentiment:\", \"You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: The movie was terrible, boring and too long.\\nSentiment: NEGATIVE\\n\\nReview: Absolutely fantastic! I loved every minute of it.\\nSentiment: POSITIVE\\n\\nReview: I may very well be one of the few who really stuck to this film. I also saw this movie when it came out, and I agree with the last post that Up The Acedemy was way ahead of its' time. The humor in the film itself is pure MAD\\nSentiment:\", 'You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: The movie was terrible, boring and too long.\\nSentiment: NEGATIVE\\n\\nReview: Absolutely fantastic! I loved every minute of it.\\nSentiment: POSITIVE\\n\\nReview: I\\'m not a John Cleese completist (although I thought \"Fawlty Towers was brilliant), but I am a fan, and when I saw this sitting, neglected, on a shelf at my local Blockbuster, I decided to give it a try. What I got was a wonderful surprise, and one of the\\nSentiment:', 'You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: The movie was terrible, boring and too long.\\nSentiment: NEGATIVE\\n\\nReview: Absolutely fantastic! I loved every minute of it.\\nSentiment: POSITIVE\\n\\nReview: Remember the early days of Pay Per View? I do, and i can almost remember the number you had to CALL to actually rent the movie on your t.v. As a kid we always wanted to rent playboy, but this meant actually calling someone from PPV and asking to rent\\nSentiment:', \"You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: The movie was terrible, boring and too long.\\nSentiment: NEGATIVE\\n\\nReview: Absolutely fantastic! I loved every minute of it.\\nSentiment: POSITIVE\\n\\nReview: I mean really. This is not going to help the Australian film industry to make this kind of film with no values of any kind. Okay, if you're a stoner and have nothing better to do, then maybe. I think film-makers from here should try to show the rest of\\nSentiment:\", 'You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: The movie was terrible, boring and too long.\\nSentiment: NEGATIVE\\n\\nReview: Absolutely fantastic! I loved every minute of it.\\nSentiment: POSITIVE\\n\\nReview: First off... I never considered myself an Uwe Boll Hater since I think I never even saw one of his movies but after seeing this cheap excuse for a movie named \"Seed\" (which is the name of the serial killer this movie is about) I am close to joining the\\nSentiment:'], 'label': [0, 1, 0, 0, 0, 1, 1, 1, 0, 0]}\n",
      "Test size: 32\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T21:56:32.575949800Z",
     "start_time": "2026-02-03T21:56:32.486377900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def truncate_zero_shot(example):\n",
    "    # Zero-shot prompt design: No examples, just instruction\n",
    "    review_segment = \" \".join(example['text'].split()[:50])\n",
    "    prompt = (\n",
    "        \"You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\n\"\n",
    "        f\"Review: {review_segment}\\n\"\n",
    "        \"Sentiment:\"\n",
    "    )\n",
    "    return {'text': prompt, 'label': example['label']}\n",
    "\n",
    "small_zero_shot = dataset['train'].shuffle(seed=SEED).select(range(128, 160)).map(truncate_zero_shot)\n",
    "print(small_zero_shot)\n",
    "print(small_zero_shot[:10])\n",
    "print(f\"Test size: {len(small_zero_shot)}\")"
   ],
   "id": "cc3b81cfadc64fa3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 32\n",
      "})\n",
      "{'text': [\"You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: Thomas Clay has been mixing with the wrong types. That's the trouble with young people these days, they have no respect.<br /><br />Seriously this film should be avoided at all costs. The action in the main body of the film is slow and rather stodgy and ambles to the drug\\nSentiment:\", \"You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: Emily Watson's Natalia is absolutely the most loving and romantic lead character I have ever seen on a screen. She is the queen of this film beyond all doubt. Or, is she transmuted to the king? The internecine weaving of the chess games and the families' struggles for control, power,\\nSentiment:\", \"You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: This apology for a movie is about absolutely nothing! Rachel Griffiths must have needed the money. The film must have been made on a very low budget, because the lighting was non existent. I made a vow if I ever see Pete Postlesumthingor other I'll commit suicide. I'd be happy\\nSentiment:\", 'You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: Can you say \"All shock, no plot?\" There were so many unexplored directions in this movie. There was no history about the room other than the deaths. *WHY* was it evil? What made it that way? Why an \"hour\" countdown? Then, there were the unexplored things hinted at; for example\\nSentiment:', \"You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: Watched this with my girlfriend after stumbling over it while zaping channels.<br /><br />I guess we both hoped for some kind of happy family cute Christmas movie, but were extremely disappointed.<br /><br />the actor playing the soldier, seems to have 0 emotion whatsoever, his face looks the same, whether he's\\nSentiment:\", \"You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: I may very well be one of the few who really stuck to this film. I also saw this movie when it came out, and I agree with the last post that Up The Acedemy was way ahead of its' time. The humor in the film itself is pure MAD\\nSentiment:\", 'You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: I\\'m not a John Cleese completist (although I thought \"Fawlty Towers was brilliant), but I am a fan, and when I saw this sitting, neglected, on a shelf at my local Blockbuster, I decided to give it a try. What I got was a wonderful surprise, and one of the\\nSentiment:', 'You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: Remember the early days of Pay Per View? I do, and i can almost remember the number you had to CALL to actually rent the movie on your t.v. As a kid we always wanted to rent playboy, but this meant actually calling someone from PPV and asking to rent\\nSentiment:', \"You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: I mean really. This is not going to help the Australian film industry to make this kind of film with no values of any kind. Okay, if you're a stoner and have nothing better to do, then maybe. I think film-makers from here should try to show the rest of\\nSentiment:\", 'You are a sentiment classifier. Determine if the following movie reviews are POSITIVE or NEGATIVE.\\n\\nReview: First off... I never considered myself an Uwe Boll Hater since I think I never even saw one of his movies but after seeing this cheap excuse for a movie named \"Seed\" (which is the name of the serial killer this movie is about) I am close to joining the\\nSentiment:'], 'label': [0, 1, 0, 0, 0, 1, 1, 1, 0, 0]}\n",
      "Test size: 32\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "bd2ef394",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "de48c031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T21:56:33.503029700Z",
     "start_time": "2026-02-03T21:56:32.580258800Z"
    }
   },
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=False)\n",
    "print(tokenizer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenizersBackend(name_or_path='microsoft/Phi-3-mini-4k-instruct', vocab_size=32000, model_max_length=4096, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '<|endoftext|>', 'unk_token': '<unk>', 'pad_token': '<|endoftext|>'}, added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t32000: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32001: AddedToken(\"<|assistant|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32002: AddedToken(\"<|placeholder1|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32003: AddedToken(\"<|placeholder2|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32004: AddedToken(\"<|placeholder3|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32005: AddedToken(\"<|placeholder4|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32006: AddedToken(\"<|system|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32007: AddedToken(\"<|end|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32008: AddedToken(\"<|placeholder5|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32009: AddedToken(\"<|placeholder6|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32010: AddedToken(\"<|user|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset preprocessing",
   "id": "2c71a46812bf336f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T21:56:33.612680300Z",
     "start_time": "2026-02-03T21:56:33.561271500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocessing is not strictly needed for direct prompting as we iterate over the dataset\n",
    "# but we keep it here if needed for future use or just skip it.\n",
    "# We will use the un-tokenized datasets `small_few_shot` and `small_zero_shot` directly in `evaluate_prompting`."
   ],
   "id": "31c560084f74c848",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Definition",
   "id": "1edc980af9693b4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T21:56:36.069576100Z",
     "start_time": "2026-02-03T21:56:33.612680300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = AutoConfig.from_pretrained(MODEL_NAME, trust_remote_code=False)\n",
    "# IMPORTANT: Do not set rope_scaling to None on Phi-3 configs with transformers>=5.\n",
    "# Doing so will set rope_parameters=None internally and crash the native Phi3 implementation.\n",
    "# Leave the default as-is; if needed, adjust rope_type explicitly (e.g., to 'linear').\n",
    "# Example of safe adjustment (commented out):\n",
    "# if isinstance(config.rope_scaling, dict) and config.rope_scaling.get(\"rope_type\") == \"default\":\n",
    "#     config.rope_scaling[\"rope_type\"] = \"linear\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    config=config,\n",
    "    trust_remote_code=False, \n",
    "    torch_dtype=\"auto\", \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "def get_sentiment(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=5)\n",
    "    \n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Extract the part after \"Sentiment:\"\n",
    "    prediction_part = decoded[len(prompt):].strip().upper()\n",
    "    \n",
    "    if \"POSITIVE\" in prediction_part:\n",
    "        return 1\n",
    "    elif \"NEGATIVE\" in prediction_part:\n",
    "        return 0\n",
    "    else:\n",
    "        # Fallback/heuristic if the model doesn't output exactly what we want\n",
    "        return 0 \n",
    "\n",
    "def evaluate_prompting(dataset_to_eval):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    start_time = time.perf_counter()\n",
    "    for example in tqdm(dataset_to_eval):\n",
    "        preds.append(get_sentiment(example['text']))\n",
    "        labels.append(example['label'])\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    duration = end_time - start_time\n",
    "    samples_per_second = len(dataset_to_eval) / duration if duration > 0 else 0\n",
    "    \n",
    "    preds = np.array(preds)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": np.mean(preds == labels),\n",
    "        \"f1\": f1_score(labels, preds, average='weighted'),\n",
    "        \"runtime\": duration,\n",
    "        \"samples_per_second\": samples_per_second\n",
    "    }"
   ],
   "id": "30dfd0ff211ffec5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/195 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f46c027be9ef48629f5af461c7365e7e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Execution",
   "id": "2982fa4489e26e6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T21:56:44.399926300Z",
     "start_time": "2026-02-03T21:56:36.121921500Z"
    }
   },
   "cell_type": "code",
   "source": "results_few_shot = evaluate_prompting(small_few_shot)",
   "id": "dc2c4c7968a2f1f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c335078fd0cb4e80a616980b533aa8e7"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T21:56:53.022870400Z",
     "start_time": "2026-02-03T21:56:44.451108800Z"
    }
   },
   "cell_type": "code",
   "source": "results_zero_shot = evaluate_prompting(small_zero_shot)",
   "id": "c98c20df80e5b5ed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "330bee81bbfc49f592492ace8da3a46a"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Comparison\n",
    "\n",
    "Note: Prompting using Phi-3 (3.8B parameters) is significantly more computationally expensive than classic fine-tuning with DistilBERT (~66M parameters) because it involves autoregressive generation of multiple tokens instead of a single forward pass for classification."
   ],
   "id": "ae3c37a744f3a606"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"--- FINAL COMPARISON ---\")\n",
    "print(f\"Model used: {MODEL_NAME}\")\n",
    "print(f\"{'Metric':<30} | {'Few-Shot':<15} | {'Zero-Shot':<15}\")\n",
    "print(\"-\" * 66)\n",
    "print(f\"{'Accuracy':<30} | {results_few_shot['accuracy']:.4f}  | {results_zero_shot['accuracy']:.4f}\")\n",
    "print(f\"{'F1 Score':<30} | {results_few_shot['f1']:.4f}  | {results_zero_shot['f1']:.4f}\")\n",
    "print(f\"{'Inference Time (s)':<30} | {results_few_shot['runtime']:.4f}  | {results_zero_shot['runtime']:.4f}\")\n",
    "print(f\"{'Inference Speed (samples/s)':<30} | {results_few_shot['samples_per_second']:.4f}  | {results_zero_shot['samples_per_second']:.4f}\")"
   ],
   "id": "406f6994f9369119"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyatom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
